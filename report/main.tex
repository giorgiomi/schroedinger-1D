\documentclass[a4paper, titlepage]{article}
\input{packages}
\numberwithin{equation}{section}

%%% Il documento vero e proprio %%%
\begin{document}
\input{frontespizio}
\newcommand{\sch}[0]{Schrödinger }

\section{Introduzione}
L'obiettivo di questo progetto è risolvere numericamente l'equazione di Schrödinger in una dimensione:
\begin{equation}
    i\frac{\partial}{\partial t}\psi(x,t) = \left[-\frac{1}{2}\frac{\partial^2}{\partial x^2} + V(x)\right]\psi(x,t)\, .
    \label{eq:sch}
\end{equation}
Per semplicità, si sono posti $\hbar = m = 1$. Si è interessati alla regione $x \in [-L,L]$ e si impongono le condizioni al contorno $\psi(-L,t) = \psi(L,t) = 0$. Si vogliono studiare i casi di particella libera $V(x) = 0$ e di potenziale a doppia buca $V(x) = V_0(x^2-a)^2$.

\subsection{Metodo di Eulero esplicito}
Il primo approccio è quello di utilizzare il metodo di Eulero esplicito. 
Per prima cosa, si usano le differenze finite per stimare le derivate della funzione d'onda che compaiono in \eqref{eq:sch}. Valutando le derivate in $(x_0, t_0)$, si ottiene:
\begin{align*}
    &\left.\pdv{\psi(x, t)}{t}\right\vert_{(x_0, t_0)} = \frac{\psi(x_0, t_0 + \Delta t) - \psi(x_0, t_0)}{\Delta t} + \mathcal{O}(\Delta t)\, , \\
    &\left.\pdv[2]{\psi(x, t)}{x}\right\vert_{(x_0, t_0)} = \frac{\psi(x_0 + \Delta x, t_0) - 2\psi(x_0, t_0) + \psi(x_0 - \Delta x, t)}{\Delta x^2} + \mathcal{O}(\Delta x^2)\, .
\end{align*}
L'equazione di Schrödinger diventa quindi:
\begin{equation*}
    i \frac{\psi(x_0, t_0 + \Delta t) - \psi(x_0, t_0)}{\Delta t} = 
    - \frac{\psi(x_0 + \Delta x, t_0) - 2\psi(x_0, t_0) + \psi(x_0 - \Delta x, t_0)}{2\Delta x^2} + V(x_0)\psi(x_0, t_0)\, .
\end{equation*}
Prendendo $\Delta x = 2L/(N+1)$, si possono definire la funzione d'onda e il potenziale calcolati sui punti della griglia come
\begin{align*}
    &\psi_i^k = \psi(-L + i\Delta x, t_0 + k\Delta t) \qquad i = 0,1,\dots,N+1 \quad k = 0,1,\dots,M \\
    &V_i = V(-L + i\Delta x) \qquad\qquad\qquad\ i = 0,1,\dots,N+1
\end{align*}
e si può scrivere l'equazione in modo più chiaro:
\begin{equation*}
    i \frac{\psi_i^{k+1} - \psi_i^k}{\Delta t} = 
    - \frac{\psi_{i+1}^k - 2\psi_i^k + \psi_{i-1}^k}{2\Delta x^2} + V_i\psi_i^k\, .
\end{equation*}
Isolando il termine $\psi_i^{k+1}$ e semplificando, si ottiene
\begin{equation}
    \psi_i^{k+1} = \eta \psi_{i+1}^k + (1 - 2\eta + \Delta\tau V_i)\psi_i^k + \eta\psi_{i-1}^k\, ,
    \label{eq:evol}
\end{equation}
dove $\Delta\tau = -i\Delta t$ e $\eta = - \Delta\tau/2\Delta x^2$. L'equazione \eqref{eq:evol} rappresenta l'evoluzione temporale della funzione d'onda. Come ultimo passaggio, si può definire il vettore
\begin{equation*}
    \bm{\psi}_k = (\psi_1^k,\psi_2^k,\dots,\psi_N^k)^T
\end{equation*}
e l'equazione diventa
\begin{equation}
    \bm{\psi}_{k+1} = A\bm{\psi}_k
    \label{eq:evol_mat}
\end{equation}
con
\begin{equation*} 
    A = \begin{pmatrix}
    1-2\eta + \Delta\tau V_1 & \eta & 0 & \cdots & 0 \\
    \eta & 1-2\eta + \Delta\tau V_2 & \eta & \cdots & 0 \\
     0 & \eta & 1-2\eta + \Delta\tau V_3 & \cdots & 0 \\
    \vdots & \vdots & \vdots & \ddots & \eta \\
    0 & 0 & 0 & \eta & 1-2\eta + \Delta\tau V_N 
    \end{pmatrix}\, . 
\end{equation*}
La matrice $A$ è tridiagonale: ciò semplifica molto la computazione della moltiplicazione matrice per vettore. Inoltre, scrivendo $A = \mathbb{1} - i\Delta t H$, si ottiene direttamente la matrice Hamiltioniana, che è indipendente dal passo temporale $\Delta t$.

\subsection{Metodo di Crank-Nicolson}
Il metodo di Crank-Nicolson combina mezzo passo del metodo di Eulero esplicito con mezzo passo del metodo implicito. Utilizzando la matrice $H$ appena calcolata, il passo esplicito da fare è \footnote{Mentre la notazione $\bm{\psi}_k$ corrisponde a $\bm{\psi}(t)$, la notazione $\bm{\psi}_{k+1/2}$ corrisponde a $\bm{\psi}(t+\Delta t/2)$}
\begin{equation*}
    \bm{\psi}_{k+1/2} = \left(\mathbb{1} - i\frac{\Delta t}{2} H\right)\bm{\psi}_k\, ,
\end{equation*}
seguito dal passo implicito, cioè
\begin{equation*}
    \left(\mathbb{1} + i\frac{\Delta t}{2} H\right)\bm{\psi}_{k+1} = \bm{\psi}_{k+1/2}\, .
\end{equation*}
Per risolvere il passo implicito, sia $M = \left(\mathbb{1} + i\frac{\Delta t}{2} H\right)$. Come si è già visto, questa matrice è tridiagonale e può essere fattorizzata nel seguente modo:
\begin{equation*} 
    M = 
    \begin{pmatrix}
        a_1 & c_1 & 0 & 0 & \cdots \\
        e_2 & a_2 & c_2 & 0 & \cdots \\
        0 & e_3 & a_3 & c_3 & \cdots \\
        0 & 0 & e_4 & a_4 & \cdots \\
        \vdots & \vdots & \vdots & \vdots & \ddots 
    \end{pmatrix} = 
    \begin{pmatrix}
        1 & 0 & 0 & 0 & \cdots \\
        \beta_2 & 1 & 0 & 0 & \cdots \\
        0 & \beta_3 & 1 & 0 & \cdots \\
        0 & 0 & \beta_4 & 1 & \cdots \\
        \vdots & \vdots & \vdots & \vdots & \ddots 
    \end{pmatrix}
    \begin{pmatrix}
        \alpha_1 & \gamma_1 & 0 & 0 & \cdots \\
        0 & \alpha_2 & \gamma_2 & 0 & \cdots \\
        0 & 0 & \alpha_3 & \gamma_3 & \cdots \\
        0 & 0 & 0 & \alpha_4 & \cdots \\
        \vdots & \vdots & \vdots & \vdots & \ddots 
    \end{pmatrix}
    = LU\, .
\end{equation*}
Nel caso considerato, i coefficienti di $M$ sono
\begin{equation*}
    a_i = 1 + \eta - V_i \frac{\Delta\tau}{2}\, , \qquad\qquad
    c_i = e_i = -\frac{\eta}{2}
\end{equation*}
e da questi si possono ricavare quelli di $L$ e $U$ partendo da $\alpha_1 = a_1$:
\begin{equation}
    \beta_i = -\frac{\eta}{2\alpha_{i-1}}\, ,
    \qquad
    \gamma_i = -\frac{\eta}{2}\, ,
    \qquad
    \alpha_i = a_i - \frac{\eta^2}{4\alpha_{i-1}}\, .
    \label{eq:recZ}
\end{equation}
Infine, per risolvere $LU\mathbf{x} = \mathbf{b}$, con $\mathbf{x} = \bm{\psi}_{k+1}$ e $\mathbf{b} = \bm{\psi}_{k+1/2}$, si risolve prima ricorsivamente $L\mathbf{y} = \mathbf{b}$:
\begin{equation}
    y_1 = b_1 \qquad y_i = b_i -\beta_i y_{i-1} \qquad i = 2,\dots,N
    \label{eq:recA}
\end{equation}
e poi ricorsivamente $U\mathbf{x} = \mathbf{y}$:
\begin{equation}
    x_N = \frac{y_N}{\alpha_N} \qquad x_i = \frac{y_i}{\alpha_i} - \frac{x_{i+1}\gamma_i}{\alpha_i} \qquad i = N-1,\dots,0\, .
    \label{eq:recB}
\end{equation}

\subsection{Metodo di Trotter-Suzuki}
Questo metodo prevede di trattare l'evoluzione temporale scrivendo la soluzione esatta
\begin{equation*}
    \bm{\psi}_{k+1} = \exp(-i\Delta t H)\bm{\psi}_k\, ,
\end{equation*}
di cui equazione \eqref{eq:evol_mat} è un'approssimazione al primo ordine in $\Delta t$. Per poter applicare l'esponenziale alla funzione d'onda, si usa l'approssimazione di Trotter-Suzuki:
\begin{equation*}
    \exp(-i \Delta t H) = \exp\left(-i \frac{\Delta t}{2} V\right) \exp(-i \Delta t T) \exp\left(-i \frac{\Delta t}{2} V\right) + \mathcal{O}(\Delta t^3)\, .
\end{equation*}
Siccome $V = \text{diag}(V_1,\dots,V_N)$, è facile calcolarne l'esponenziale, che sarà
\[
    \exp(-i\frac{\Delta t}{2} V) = \text{diag}\left(\exp(-i\frac{\Delta t}{2} V_1),\dots,\exp(-i\frac{\Delta t}{2} V_N)\right)\, .
\]
La matrice $T$ non è diagonale, bensì tridiagonale. Inoltre gli elementi sulla diagonale principale sono uguali e corrispondono ad $a_i = 1/\Delta x^2$. Anche gli elementi sulle altre diagonali sono uguali, e sono $c_i = e_i = -1/2\Delta x^2$. Si tratta perciò anche di una matrice di Töplitz, i cui autovalori e autovettori sono facili da calcolare, e sono, in questo caso:
\[
    \lambda_n = \frac{1}{\Delta x^2} \left[1 -\cos\left(\frac{n\pi}{N+1}\right)\right]\, ,
    \qquad
    (v_n)_k = \sin\left(\frac{nk\pi}{N+1}\right)\, .
\]
Una volta diagonalizzata la matrice $T = P^{-1}DP$, dove $P$ è la matrice di cambio di base e $D$ è la matrice diagonale, se ne può calcolare l'esponenziale $\exp(-i\Delta t T) = P^{-1}\exp(-i\Delta t D)P$.


\section{Simulazione di particella libera}
Il caso in cui $V(x) = 0$ è quello di particella libera. Al fine di normalizzare la funzione d'onda, si usa come condizione iniziale
\begin{equation}
    \psi(x = 0, 0) = \frac{1}{\sqrt{\Delta x}}\, ,
    \qquad
    \psi(x,0) = 0\ \forall x \neq 0\, .
    \label{eq:initial}
\end{equation}
Si fanno andare le simulazioni con $N = 199$ divisioni spaziali, $\Delta x = \num{1e-2}$, $L=1$, $M = \num{3e4}$ passi temporali, $\Delta t = \num{1e-6}$. 

La struttura delle simulazioni con i due metodi è semplice:
\begin{itemize}
    \item Nel caso del metodo di Eulero esplicito, ad ogni passo basta effettuare la moltiplicazione matrice per vettore di equazione \eqref{eq:evol_mat}. Come già accennato, siccome la matrice è tridiagonale, la computazione è meno dispendiosa: si tratta di un algoritmo $\mathcal{O}(N)$ invece che $\mathcal{O}(N^2)$, dove la matrice è $N\times N$.
    \item Per il metodo di Crank-Nicolson invece, per ogni passo della simulazione si esegue il mezzo passo esplicito allo stesso modo di Eulero e poi si inverte la matrice del passo implicito con le regole di ricorsione \eqref{eq:recZ}, \eqref{eq:recA} e \eqref{eq:recB}, che sono anch'esse implementabili in $\mathcal{O}(N)$.
\end{itemize}

Per studiare il comportamento di entrambi i metodi, si calcola ad ogni passo temporale la normalizzazione della funzione d'onda, cioè
\[
    \mathcal{N}(t) = \int_{-L}^L |\psi(x,t)|^2 \dd{x}\, .
\]
\begin{figure}[h!]
    \centering
    \begin{minipage}{0.47 \textwidth}
        \centering
        \includegraphics[width = \linewidth]{figures/norm.png}
        \caption{Evoluzione temporale della normalizzazione della funzione d'onda nei due metodi (asse verticale in scala logaritmica)}
        \label{fig:norm}
    \end{minipage}
    \hspace{0.02\textwidth}
    \begin{minipage}{0.47 \textwidth}
        \centering
        \includegraphics[width = \linewidth]{figures/pos.png}
        \caption{Evoluzione temporale del valore di aspettazione $\langle x \rangle$ e di $\sigma_x$ nella simulazione con Crank-Nicolson}
        \label{fig:pos}
    \end{minipage}
\end{figure}
Siccome la simulazione genera valori $\psi_i^k$ su uno spazio discreto, l'integrale si deve calcolare sommando i contributi di ogni divisione spaziale, ricordandosi che le condizioni al contorno annullano i contributi a $x = \pm L$.
Naturalmente ci si aspetta di avere $\mathcal{N}(t) = 1$, ma come si può notare in figura \ref{fig:norm} il metodo di Eulero viola questa condizione e $\mathcal{N}(t)$ cresce esponenzialmente!\footnote{Questa è solo una stima visiva dal grafico.}
Il problema risiede proprio nel fatto che il metodo è di tipo esplicito e, come per le equazioni differenziali ordinarie, la convergenza non è garantita. 

È conveniente dunque affidarsi al metodo di Crank-Nicolson, del quale si verifica la corretta implementazione mostrando l'evoluzione temporale del valor medio $\langle x \rangle$ e della deviazione standard $\sigma_x = \sqrt{\langle x^2 \rangle - \langle x \rangle^2}$ in figura \ref{fig:pos}. Come ci si aspetta (si veda l'appendice \ref{sec:evol}), il valor medio della posizione $x$ è nullo e la deviazione standard cresce linearmente nel tempo, almeno fino al raggiungimento dei lati della scatola.


\section{Simulazione con potenziale a doppia buca}

Ora viene simulato il sistema con potenziale $V(x) = V_0(x^2-a)^2$. In generale, i due minimi del potenziale si trovano a $x_{1,2} = \pm \sqrt{a}$, quindi come condizione iniziale si può prendere la stessa di equazione \eqref{eq:initial} ma con la funzione d'onda in $x_1 = -\sqrt{a}$ (la buca di sinistra). 

\subsection{Frequenza di oscillazione}

È di particolare interesse calcolare la probabilità di misurare la particella in ciascuna delle due buche in funzione del tempo, e si può fare semplicemente così:
\[
    \mathcal{P}_L(t) = \int_{-L}^0 |\psi(x,t)|^2 \dd x\, ,
    \qquad
    \mathcal{P}_R(t) = \int_0^L |\psi(x,t)|^2 \dd x\, .
\]
Prendendo $N$ dispari, bisogna decidere se inserire il contributo centrale in $\mathcal{P}_L$ o  $\mathcal{P}_R$, ma in ogni caso ciò non è rilevante ai risultati della simulazione per $N$ abbastanza grande. 

Per quanto riguarda i valori dei parametri $V_0$ e $a$, si può notare che $V(0) = V_0 a^2$, e questo stabilisce un ordine di grandezza per la doppia buca. Nel mezzo passo esplicito del metodo di Crank-Nicolson, la matrice di evoluzione temporale ha come valori della diagonale $1-\eta + \frac{\Delta\tau}{2} V_i$, e ciò suggerisce che l'ordine di grandezza del potenziale, per avere un contributo significativo, debba essere
\begin{equation}
    |\Delta\tau| V_i \sim 1 
    \qquad \Rightarrow \qquad
    V_0 a^2 \sim \frac{1}{\Delta t}\, .
    \label{eq:extim}
\end{equation}
\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.47 \textwidth}
        \centering
        \includegraphics[width = \linewidth]{figures/prob_null.png}
        \caption{Oscillazione di probabilità nella simulazione con doppia buca di potenziale. Quando $V_0 = 0$ e $a = 0$, non c'è oscillazione.}
        \label{fig:prob_null}
    \end{minipage}
    \hspace{0.02\textwidth}
    \begin{minipage}[t]{0.47 \textwidth}
        \centering
        \includegraphics[width = \linewidth]{figures/prob_osc.png}
        \caption{Oscillazione di probabilità nella simulazione con doppia buca di potenziale. Quando il potenziale è basso, la particella non è confinata nella buca di partenza, e oscilla tra le due in modo simile al caso $V_0 = 0$, $a \neq 0$.}
        \label{fig:prob_osc}
    \end{minipage}
\end{figure}
Quindi tenendo il valore $\Delta t = \num{1e-6}$, i valori $V_0 = 1$ e $a = 0.25$ produrrebbero un potenziale troppo debole. Si decide quindi di usare un passo $\Delta t = \num{1e-4}$ e poi andare a studiare il comportamento della simulazione per diversi valori di $V_0$ e $a$.
% si usano $V_0 = \num{1e3}$ e $a = 0.25$.
Nelle figure \ref{fig:prob_null}, \ref{fig:prob_osc} e \ref{fig:prob_sep} si mostrano i risultati in tre esempi diversi:
\begin{itemize}
    \item Nel primo caso, $V_0 = 0$ e $a = 0$, quindi il potenziale è nullo e la particella libera si muove nella scatola. Partendo dal centro della scatola, non c'è oscillazione nella probabilità di misurarla a sinistra o destra ed entrambe valgono $\sim 0.5$.
    \item Il secondo caso ha $V_0 a^2 = \num{2.5e2}$. Ora la particella oscilla tra le due buche, ma il potenziale è ancora troppo basso purché resti confinata in una delle due. Questo caso è molto simile a $V_0 = 0$, $a \neq 0$, siccome il potenziale è ancora trascurabile rispetto all'energia cinetica.
    \item Nel terzo caso, $V_0 a^2 = \num{1.8e4}$. In accordo con la previsione di equazione \eqref{eq:extim}, a questo ordine di grandezza la particella risente del potenziale ed è quasi completamente confinata nella buca di partenza (sinistra).
\end{itemize}
\begin{figure}[h!]
    \centering
    \begin{minipage}{0.47 \textwidth}
        \centering
        \includegraphics[width = \linewidth]{figures/prob_sep.png}
        \caption{Oscillazione di probabilità nella simulazione con doppia buca di potenziale. Quando il potenziale è alto, la particella è quasi completamente confinata nella buca di partenza.}
        \label{fig:prob_sep}
    \end{minipage}
    \hspace{0.02\textwidth}
    \begin{minipage}{0.47 \textwidth}
        % \hspace{\linewidth}
    \end{minipage}
\end{figure}
Studiare la frequenza di oscillazione del moto non è semplice. Quando il potenziale è basso e non c'è confinamento, si può stimare il periodo medio di oscillazione prendendo gli istanti temporali in cui $\mathcal{P}_L(t) = 0.5$ e calcolando la media degli intervalli tra questi istanti. Una stima dell'incertezza sul valor medio del periodo può essere fatta con la deviazione standard dei periodi (diviso la radice del numero di periodi). Quando il potenziale è troppo alto, invece, le probabilità non oscillano più attorno a $0.5$ e diventa difficile stimare i periodi. Per questo motivo, si decide di studiare solo i casi in cui il potenziale è basso.
\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.47 \textwidth}
        \centering
        \includegraphics[width = \linewidth]{figures/freq_vs_a.png}
        \caption{Stima della frequenza di oscillazione $\nu$ in funzione del parametro $a$ della doppia buca.}
        \label{fig:freq_vs_a}
    \end{minipage}
    \hspace{0.02\textwidth}
    \begin{minipage}[t]{0.47 \textwidth}
        \centering
        \includegraphics[width = \linewidth]{figures/freq_vs_V0.png}
        \caption{Stima della frequenza di oscillazione $\nu$ in funzione del parametro $V_0$ della doppia buca.}
        \label{fig:freq_vs_V0}
    \end{minipage}
\end{figure}
I risulati, mostrati in figura \ref{fig:freq_vs_a} al variare di $a$ e in figura \ref{fig:freq_vs_V0} al variare di $V_0$, mostrano una bassa variazione della frequenza di oscillazione. Tuttavia, si nota immediatamente che i dati sono dominati dall'incertezza ed è difficile stabilire un andamento anche solo qualitativo della frequenza.

\subsection{Pacchetto gaussiano}
Per provare a migliorare i risultati della simulazione, si può provare ad implementare una diversa condizione iniziale. Il problema della funzione d'onda di equazione \eqref{eq:initial} è la discontinuità. Infatti, sebbene l'evoluzione con il metodo di Crank-Nicolson fornisca risultati fisici (la normalizzazione è conservata), la simulazione è molto influenzata dal passo spaziale $\Delta x$. Si decide dunque di utilizzare all'istante iniziale un pacchetto gaussiano del tipo:
\begin{equation*}
    \psi(x, 0) = \left(\frac{1}{2\pi\sigma^2}\right)^{1/4}\exp{-\frac{(x-x_1)^2}{4\sigma^2}}\, .
\end{equation*}
Si noti che questa scelta fa sì che $\int_{-\infty}^{+\infty} |\psi(x,0)|^2 \dd x = 1$ e, in generale, la funzione d'onda è non nulla anche al di fuori della scatola. Tuttavia, si può prendere una larghezza piccola della funzione gaussiana, corrispondente ad un pacchetto ben localizzato attorno a $x = x_1$, e i contributi esterni alla scatola diventano trascurabili.\footnote{Il problema persiste se si prende $a \to 1$ e quindi $x_1 \to -1$. In questo caso il pacchetto gaussiano non è normalizzato.} 
Si decide quindi di prendere $\sigma = \sqrt{\Delta x}$.
\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.47 \textwidth}
        \centering
        \includegraphics[width = \linewidth]{figures/gauss_prob.png}
        \caption{Oscillazioni di probabilità nella simulazione con pacchetto gaussiano come condizione iniziale. Le oscillazioni sono più ampie e la particella si muove effettivamente tra le due buche.}
        \label{fig:gauss_prob}
    \end{minipage}
    \hspace{0.02\textwidth}
    \begin{minipage}[t]{0.47 \textwidth}
        \centering
        \includegraphics[width = \linewidth]{figures/gauss_energy.png}
        \caption{Energia del sistema nella simulazione con pacchetto gaussiano come condizione iniziale. Entro un piccolo scarto, l'energia totale è conservata.}
        \label{fig:gauss_energy}
        % \hspace{\linewidth}
    \end{minipage}
\end{figure}

Si mostrano i risultati di una simulazione con $N = 199$, $\Delta t = \num{1e-3}$, $V_0 = 100$, $a = 0.25$. In figura \ref{fig:gauss_prob}, si mostrano le oscillazioni di probabilità: rispetto alla simulazione precedente, l'ampiezza è aumentata, ciò significa che ci sono degli istanti periodici in cui la particella è quasi totalmente localizzabile in una delle due buche. Rimane tuttavia ancora non banale stimare la frequenza di oscillazione, un modo alternativo per effettuare la stima potrebbe essere quello di prendere in considerazione i picchi della funzione di probabilità. Per verificare ulteriormente la correttezza della simulazione, in figura \ref{fig:gauss_energy} si mostrano i valori di aspettazione dell'energia del sistema in funzione del tempo. Sono calcolati nel seguente modo:
\begin{align*}
    &\langle T \rangle = \langle \psi(x,t) | T | \psi(x,t) \rangle = \int_{-L}^{L} \psi^*(x,t) \left(-\frac{1}{2}\pdv[2]{x}\right)\psi(x,t) \dd x\, , \\
    &\langle V \rangle = \langle \psi(x,t) | V | \psi(x,t) \rangle = \int_{-L}^{L} \psi^*(x,t) V(x) \psi(x,t) \dd x = \int_{-L}^{L} V(x) |\psi(x,t)|^2 \dd x\, .
\end{align*}
In figura si nota che l'energia totale $\langle H \rangle = \langle T \rangle  + \langle V \rangle$, entro un piccolo scarto, è conservata nel tempo.
Si riscontra, tuttavia, che l'energia totale dipende dal numero $N$ di divisioni spaziali e quindi dal passo $\Delta x$. Questo è probabilmente imputabile al calcolo dell'energia cinetica con le differenze finite, siccome al denominatore appare il termine $\Delta x^2$ e la dipendenza sembra essere proprio $\langle T \rangle \sim N^2$ ad una prima analisi qualitativa. 

Ciò rende difficile il controllo sulla stabilità al variare di $N$, anche se qualitiativamente la forma delle oscillazioni di probabilità rimane la stessa per $100 \lesssim N \lesssim 400$. La stabilità con passi temporali diversi è invece verificata, a patto di non scegliere $\Delta t \gtrsim 10^{-2}$: un passo troppo grande invalida l'evoluzione temporale del sistema.

\subsection{Trotter-Suzuki}
Infine, si mostrano i risultati ottenuti con il metodo di Trotter-Suzuki in figura \ref{fig:gauss_prob_compare} e \ref{fig:gauss_energy_compare}, per una simulazioni con gli stessi parametri della precedente e il pacchetto gaussiano come condizione iniziale.
\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.47 \textwidth}
        \centering
        \includegraphics[width = \linewidth]{figures/gauss_prob_compare.png}
        \caption{Confronto delle oscillazioni di probabilità tra i due metodi. I risultati sono molto simili.}
        \label{fig:gauss_prob_compare}
    \end{minipage}
    \hspace{0.02\textwidth}
    \begin{minipage}[t]{0.47 \textwidth}
        \centering
        \includegraphics[width = \linewidth]{figures/gauss_energy_compare.png}
        \caption{Confronto dei valori di aspettazione dell'energia tra i due metodi. I risultati sono molto simili.}
        \label{fig:gauss_energy_compare}
        % \hspace{\linewidth}
    \end{minipage}
\end{figure}
Si nota che le simulazioni forniscono risultati in accordo e molto simili. Ciò evidenzia la bontà dell'approssimazione al primo ordine in Crank-Nicolson, che lo rende probabilmente il metodo più conveniente, a causa dell'elevata complessità computazionale di Trotter-Suzuki ($\mathcal{O}(N^3)$!).


\section{Conclusioni}
Il metodo di Eulero esplicito, sebbene semplice da implementare, ha mostrato problemi di stabilità e conservazione della normalizzazione della funzione d'onda. Questo metodo, infatti, tende a far crescere esponenzialmente la normalizzazione, rendendolo inadatto per simulazioni a lungo termine.

Il metodo di Crank-Nicolson, invece, ha garantito una buona conservazione della normalizzazione e dell'energia del sistema, risultando più affidabile per le simulazioni a lungo termine. Questo metodo combina un passo esplicito e uno implicito, permettendo di mantenere la stabilità numerica e di ottenere risultati fisicamente significativi. La sua implementazione ha dimostrato inoltre di essere efficiente dal punto di vista computazionale.

Infine, il metodo di Trotter-Suzuki ha fornito risultati in accordo con quelli di Crank-Nicolson, ma con una complessità computazionale maggiore. La necessità di diagonalizzare la matrice di Töplitz e di eseguire delle moltiplicazioni tra matrici non tridiagonali rende questo metodo meno conveniente per simulazioni su larga scala.

Pertanto, per simulazioni efficienti e accurate, il metodo di Crank-Nicolson si è rivelato il più conveniente. Le simulazioni hanno permesso di studiare il comportamento di una particella libera e di una particella in un potenziale a doppia buca, evidenziando l'importanza della scelta delle condizioni iniziali e dei parametri del potenziale per ottenere risultati fisicamente significativi. In particolare, l'uso di un pacchetto gaussiano come condizione iniziale ha migliorato la stabilità e l'accuratezza delle simulazioni, permettendo di osservare chiaramente le oscillazioni di probabilità tra le due buche del potenziale.




\pagebreak
\appendix

\section{Evoluzione temporale e valori di aspettazione}
\label{sec:evol}
Data l'equazione di Schrödinger
\[
    i\pdv{t}|\psi(t)\rangle = H|\psi(t)\rangle 
    \qquad \text{con} \qquad
    H = -\pdv[2]{x} = \frac{p^2}{2}\, ,
\]
si vogliono calcolare i valori di aspettazione $\langle\psi(t)|x|\psi(t)\rangle$ e $\langle\psi(t)|x^2|\psi(t)\rangle$. Lo stato all'istante $t$ è determinato dall'operatore di evoluzione temporale:
\[
    |\psi(t)\rangle = U(t)|\psi(t)\rangle = e^{-itH} |\psi(0)\rangle\, .
\]
Il valore di aspettazione di $x$ risulta perciò
\begin{equation}
    \langle\psi(t)|x|\psi(t)\rangle = \langle\psi(0)|U^\dagger(t) x U(t)|\psi(0)\rangle = \langle\psi(0)|x_H(t)|\psi(0)\rangle\, ,
    \label{eq:exp_x}
\end{equation}
dove si è definito l'operatore $x_H(t)$ in rappresentazione di Heisenberg. La sua evoluzione è dettata dall'equazione di Heisenberg per gli operatori:
\[
    i\dv{t}x_H(t) = [x_H(t), H]\, .
\]
È facile far vedere che il commutatore a destra dell'equazione è $[x_H(t), H] = ip$, e quindi l'operatore posizione è 
\[
    x_H(t) = x_H(0) + pt\, .
\]
Ora si può usare l'equazione \eqref{eq:exp_x} sostituendo la forma dell'operatore $x_H(t)$ e si ottiene
\begin{equation*}
    \langle x \rangle = \langle\psi(0)|x(0)|\psi(0)\rangle + \langle\psi(0)|p|\psi(0)\rangle t\, ,
\end{equation*}
dove si è sfruttato il fatto che $x_H(0) = x(0)$. Il primo termine si annulla prendendo come stato iniziale l'autostato della posizione $|x = 0\rangle$. Il secondo termine è nullo perché l'operatore $p$ è dispari e lo stato iniziale, invece, è pari. Quindi, in queste condizioni, $\langle x \rangle = 0$. Allo stesso modo si calcola il valore di aspettazione di $x^2$:
\begin{equation*}
    \langle x^2 \rangle = \langle\psi(0)|p^2|\psi(0)\rangle t^2\, ,
\end{equation*}
che non si annulla perché $p^2$ è pari. Infine, la deviazione standard è
\[
    \sigma_x = \sqrt{\langle x^2 \rangle - \langle x \rangle^2} = \sqrt{\langle x^2 \rangle} \propto t\, .
\]

\end{document}